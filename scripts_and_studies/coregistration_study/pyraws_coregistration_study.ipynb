{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PyRaws - RAW Granule filtering notebook. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This notebook is a demonstrator of the effects of the lack of a preprocessing to onboard classification. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "notebookRunGroups": {
                    "groupValue": "1"
                }
            },
            "source": [
                "# 1) - Imports, paths and variables"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Limit CUDA visible devices."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "notebookRunGroups": {
                    "groupValue": "1"
                }
            },
            "outputs": [],
            "source": [
                "import os\n",
                "os.environ['CUDA_VISIBLE_DEVICES']='0'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Autoreload."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "notebookRunGroups": {
                    "groupValue": "1"
                }
            },
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Imports."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "notebookRunGroups": {
                    "groupValue": "1"
                }
            },
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "sys.path.insert(1, os.path.join(\"..\",\"..\"))\n",
                "from coregistration_study_notebooks_utils import generate_histograms\n",
                "from pyraws.utils.database_utils import DATABASE_FILE_DICTIONARY, get_cfg_file_dict\n",
                "from pyraws.utils.constants import BAND_SPATIAL_RESOLUTION_DICT\n",
                "import torch\n",
                "from tqdm import tqdm\n",
                "import numpy as np\n",
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This import is to remove odd errors on `libiomp5md.dll`. If you do not have them, you can skip it"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "notebookRunGroups": {
                    "groupValue": "1"
                }
            },
            "outputs": [],
            "source": [
                "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Set torch device. Use \"CUDA\" as default if available."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "notebookRunGroups": {
                    "groupValue": "1"
                }
            },
            "outputs": [],
            "source": [
                "if torch.cuda.is_available():\n",
                "    device=torch.device(\"cuda\")\n",
                "else:\n",
                "    device=torch.device(\"cpu\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2) - Parameters to select"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Creating a requested band list and dictionary with index positions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "notebookRunGroups": {
                    "groupValue": "1"
                }
            },
            "outputs": [],
            "source": [
                "bands = ['B02','B08','B03','B10','B04','B05','B11','B06','B07','B8A','B12','B01','B09']\n",
                "\n",
                "k=1\n",
                "requested_bands=[bands[k], bands[k+1]] #Requested bands\n",
                "requested_bands=['B8A', 'B12'] #Requested bands\n",
                "band_dict=dict(zip(requested_bands, [n for n in range(len(requested_bands))]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4) - Parsing results"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Create empty `shift_lut_db`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "database_col_names=[\"satellite\",\"registration_mode\",\"detector\",\"S08_02\",\"S03_08\",\"S10_03\",\"S04_10\",\"S05_04\",\"S11_05\",\"S06_11\",\"S07_06\",\"S8A_07\",\"S12_8A\",\"S01_12\",\"S09_01\",\"S05_03\"]\n",
                "database_row=[\"S2A\",\"downsampling\",1,[[0,0]],[[0,0]],[[0,0]],[[0,0]],[[0,0]],[[0,0]],[[0,0]],[[0,0]],[[0,0]],[[0,0]],[[0,0]],[[0,0]]]\n",
                "shift_lut_df = pd.DataFrame(data=dict(zip(database_col_names,database_row)))\n",
                "shift_lut_df=shift_lut_df.append(dict(zip(database_col_names,[\"S2A\", \"upsampling\"]+database_row[2:])), ignore_index=True)\n",
                "shift_lut_df=shift_lut_df.append(dict(zip(database_col_names,[\"S2B\"]+database_row[1:])), ignore_index=True)\n",
                "shift_lut_df=shift_lut_df.append(dict(zip(database_col_names,[\"S2B\", \"upsampling\"]+database_row[2:])), ignore_index=True)\n",
                "for n in range(2,13):\n",
                "    database_row_copy=[database_row[0],database_row[1],n]+[[0,0] for n in range(len(database_row) - 3)]\n",
                "    shift_lut_df=shift_lut_df.append(dict(zip(database_col_names,database_row_copy)), ignore_index=True)\n",
                "    shift_lut_df=shift_lut_df.append(dict(zip(database_col_names,[\"S2A\", \"upsampling\"]+database_row_copy[2:])), ignore_index=True)\n",
                "    shift_lut_df=shift_lut_df.append(dict(zip(database_col_names,[\"S2B\"]+database_row_copy[1:])), ignore_index=True)\n",
                "    shift_lut_df=shift_lut_df.append(dict(zip(database_col_names,[\"S2B\", \"upsampling\"]+database_row_copy[2:])), ignore_index=True)\n",
                "\n",
                "shift_lut_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Create EVENT/SATELLITE dictionary."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cfg=get_cfg_file_dict()\n",
                "df = pd.read_csv(os.path.join(get_cfg_file_dict()[\"database\"],\"coregistration_study_db.csv\"))\n",
                "event = df.ID_event.to_list()\n",
                "sat = df.Sat.to_list()\n",
                "event_sat_dict = {x:y for x,y in zip(event,sat)}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Path to the directory containing the study files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from glob import glob\n",
                "coregistration_study_files=os.path.join(\"coregistration_study_results\",\"coregistration_study_results_dataset_v1\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "coregistration_files=glob(os.path.join(coregistration_study_files, \"*\"))\n",
                "\n",
                "for c_file in tqdm(coregistration_files, desc=\"Processing studies...\"):\n",
                "    if c_file[-3:] != \"csv\":\n",
                "        continue\n",
                "    c_file_name=c_file.split(os.sep)[-1][20:]\n",
                "    bands=[c_file_name[1:4], c_file_name[5:8]]\n",
                "    bands=[bands[1], bands[0]]\n",
                "    study_df = pd.read_csv(c_file)\n",
                "    study_df.dropna(axis=0,subset=\"ID_event\", inplace=True)\n",
                "    #Removing duplicates due to manual merging of study files\n",
                "    study_df=study_df.drop_duplicates(keep='first')\n",
                "   \n",
                "    # Adding satellite colum to the df\n",
                "    study_event_sat=[event_sat_dict[event] for event in study_df[\"ID_event\"]] #There are repeated entries for every event because of multiple granules.\n",
                "    study_df[\"satellite\"]=study_event_sat\n",
                "    study_df_s2a=study_df[study_df[\"satellite\"] == \"S2A\"]\n",
                "    study_df_s2b=study_df[study_df[\"satellite\"] == \"S2B\"]\n",
                "    shift_mean_2a_old=\"[0,0]\"\n",
                "    shift_mean_2b_old=\"[0,0]\"\n",
                "    for detector in tqdm(range(1,13), desc= \"Processing detectors...\"):\n",
                "        try:\n",
                "            study_df_s2a_detector=study_df_s2a[study_df_s2a[\"detector_number\"]== detector]\n",
                "            column_name=\"S\"+bands[0][1:]+\"_\"+bands[1][1:]\n",
                "            shift_mean_2a=[int(np.round(np.array(study_df_s2a_detector.N_v.to_list()).mean())),int(np.round(np.array(study_df_s2a_detector.N_h.to_list()).mean()))]\n",
                "            shift_mean_2a_old=[-shift_mean_2a[0], - shift_mean_2a[1]]\n",
                "\n",
                "        except:\n",
                "            print(\"Warning: fail to get values for: \", bands, detector, \". Using previous iterations values for S2A.\")\n",
                "            shift_mean_2a=shift_mean_2a_old\n",
                "\n",
                "        try:\n",
                "            study_df_s2b_detector=study_df_s2b[study_df_s2b[\"detector_number\"]== detector]\n",
                "            column_name=\"S\"+bands[0][1:]+\"_\"+bands[1][1:]\n",
                "            shift_mean_2b=[int(np.round(np.array(study_df_s2b_detector.N_v.to_list()).mean())),int(np.round(np.array(study_df_s2b_detector.N_h.to_list()).mean()))]\n",
                "            shift_mean_2b_old=[-shift_mean_2b[0], - shift_mean_2b[1]]\n",
                "\n",
                "        except:\n",
                "            print(\"Warning: fail to get values for: \", bands, detector, \". Using previous iterations values for S2B.\")\n",
                "            shift_mean_2b=shift_mean_2b_old\n",
                "\n",
                "\n",
                "        shift_lut_df.loc[(shift_lut_df[\"satellite\"] == \"S2A\") & (shift_lut_df[\"registration_mode\"] == \"downsampling\") & (shift_lut_df[\"detector\"] == detector), column_name] = \"[\"+str(shift_mean_2a[0])+\",\"+str(shift_mean_2a[1])+\"]\"\n",
                "        shift_lut_df.loc[(shift_lut_df[\"satellite\"] == \"S2A\") & (shift_lut_df[\"registration_mode\"] == \"upsampling\") & (shift_lut_df[\"detector\"] == detector), column_name] = \"[\"+str(shift_mean_2a[0])+\",\"+str(shift_mean_2a[1])+\"]\"\n",
                "        shift_lut_df.loc[(shift_lut_df[\"satellite\"] == \"S2B\") & (shift_lut_df[\"registration_mode\"] == \"downsampling\") & (shift_lut_df[\"detector\"] == detector), column_name] = \"[\"+str(shift_mean_2b[0])+\",\"+str(shift_mean_2b[1])+\"]\"\n",
                "        shift_lut_df.loc[(shift_lut_df[\"satellite\"] == \"S2B\") & (shift_lut_df[\"registration_mode\"] == \"upsampling\") & (shift_lut_df[\"detector\"] == detector), column_name] = \"[\"+str(shift_mean_2b[0])+\",\"+str(shift_mean_2b[1])+\"]\"\n",
                "shift_lut_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fix S04_10 by using S09_10."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SHIFT=[\"S05_04\",\"S11_05\",\"S06_11\", \"S07_06\",\"S8A_07\", \"S12_8A\",\"S01_12\", \"S09_01\"]\n",
                "for r in [20, 21,22,23]:\n",
                "    \n",
                "    v=-float(shift_lut_df.loc[r, \"S10_09\"][1:-1].split(\",\")[0]) * BAND_SPATIAL_RESOLUTION_DICT[\"B10\"]/BAND_SPATIAL_RESOLUTION_DICT[\"B04\"]\n",
                "    h=-float(shift_lut_df.loc[r, \"S10_09\"][1:-1].split(\",\")[1]) * min(BAND_SPATIAL_RESOLUTION_DICT[\"B10\"],20)/BAND_SPATIAL_RESOLUTION_DICT[\"B04\"]\n",
                "    for n in range(len(SHIFT)):\n",
                "        try:\n",
                "            k=float(shift_lut_df.loc[r, SHIFT[n]][1:-1].split(\",\")[0]) \n",
                "            l=float(shift_lut_df.loc[r, SHIFT[n]][1:-1].split(\",\")[1]) \n",
                "        except:\n",
                "            k=float(shift_lut_df.loc[r, SHIFT[n]][0]) \n",
                "            l=float(shift_lut_df.loc[r, SHIFT[n]][1]) \n",
                "        b=\"B\"+SHIFT[n][1:3]\n",
                "        v-=k * min(BAND_SPATIAL_RESOLUTION_DICT[b],20)/BAND_SPATIAL_RESOLUTION_DICT[\"B04\"]\n",
                "        h-=l * min(BAND_SPATIAL_RESOLUTION_DICT[b],20)/BAND_SPATIAL_RESOLUTION_DICT[\"B04\"]\n",
                "    shift_lut_df.loc[r, \"S04_10\"]=str([int(round(v)),int(round(h))])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fix S10_03 by using S05_03 and S04_10."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "SHIFT=[\"S04_10\",\"S05_04\"]\n",
                "for r in [20, 21,22,23]:\n",
                "    v=float(shift_lut_df.loc[r, \"S05_03\"][1:-1].split(\",\")[0]) * BAND_SPATIAL_RESOLUTION_DICT[\"B05\"]/BAND_SPATIAL_RESOLUTION_DICT[\"B10\"]\n",
                "    h=float(shift_lut_df.loc[r, \"S05_03\"][1:-1].split(\",\")[1]) * min(BAND_SPATIAL_RESOLUTION_DICT[\"B05\"],20)/min(BAND_SPATIAL_RESOLUTION_DICT[\"B10\"],20)\n",
                "    for n in range(len(SHIFT)):\n",
                "        try:\n",
                "            k=float(shift_lut_df.loc[r, SHIFT[n]][1:-1].split(\",\")[0]) \n",
                "            l=float(shift_lut_df.loc[r, SHIFT[n]][1:-1].split(\",\")[1]) \n",
                "        except:\n",
                "            k=float(shift_lut_df.loc[r, SHIFT[n]][0]) \n",
                "            l=float(shift_lut_df.loc[r, SHIFT[n]][1]) \n",
                "        b=\"B\"+SHIFT[n][1:3]\n",
                "\n",
                "        v-=k * BAND_SPATIAL_RESOLUTION_DICT[b]/BAND_SPATIAL_RESOLUTION_DICT[\"B10\"]\n",
                "        h-=l * min(BAND_SPATIAL_RESOLUTION_DICT[b],20)/min(BAND_SPATIAL_RESOLUTION_DICT[\"B10\"],20)\n",
                "    shift_lut_df.loc[r, \"S10_03\"]=str([int(round(v)),int(round(h))])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Path to the database_file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "out_db_path=os.path.join(cfg[\"database\"], \"shift_lut_test.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Save results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "shift_lut_df.to_csv(out_db_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 5) - Showing histograms (WIP)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Path to the B8A vs B11 bands study."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "database_results_csv=os.path.join(\"coregistration_study_results\",\"coregistration_study_results_THRAWS\",\"coregistration_study_B8A_B11_2023_2_1_20_36_8.csv\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Parsing studies results."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This analysis is performed on the final version of the dataset. So `THRAWS` will be used."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df=pd.read_csv(database_results_csv)\n",
                "results_df.drop_duplicates(inplace=True)\n",
                "results_df.reset_index(inplace=True, drop=True)\n",
                "coregistration_study_db=pd.read_csv(os.path.join(get_cfg_file_dict()[\"database\"],DATABASE_FILE_DICTIONARY[\"THRAWS\"]))\n",
                "coregistration_study_db.reset_index(inplace=True, drop=True)\n",
                "event_names=results_df[\"ID_event\"]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Generate histograms for N_h, for different S-2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Sat_col = [coregistration_study_db[coregistration_study_db[\"ID_event\"] ==x][\"Sat\"].to_list()[0] for x in event_names.to_list()]\n",
                "results_df[\"Sat\"]=Sat_col\n",
                "\n",
                "results_df_Nh_S2A = results_df[results_df['Sat']=='S2A'].N_h.to_list()\n",
                "results_df_Nh_S2B = results_df[results_df['Sat']=='S2B'].N_h.to_list()\n",
                "results_df_Nh = results_df.N_h.to_list()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set_style(\"whitegrid\")\n",
                "################################################################\n",
                "data = results_df_Nh\n",
                "# Plot the histogram\n",
                "plt.figure(figsize=(2,2), dpi=400)\n",
                "sns.histplot(data, bins=20, kde=True)\n",
                "\n",
                "# Add a title and labels to the plot\n",
                "plt.title(\"Sentinel-2A\")\n",
                "plt.xlabel(\"\")\n",
                "plt.ylabel(\"\")\n",
                "# Show the plot\n",
                "plt.show()\n",
                "\n",
                "################################################################\n",
                "data = results_df_Nh_S2A\n",
                "# Plot the histogram\n",
                "plt.figure(figsize=(2,2), dpi=400)\n",
                "sns.histplot(data, bins=20, kde=True)\n",
                "\n",
                "# Add a title and labels to the plot\n",
                "plt.title(\"Sentinel-2A\")\n",
                "plt.xlabel(\"\")\n",
                "plt.ylabel(\"\")\n",
                "# Show the plot\n",
                "plt.show()\n",
                "\n",
                "\n",
                "################################################################\n",
                "data = results_df_Nh_S2B\n",
                "# Plot the histogram\n",
                "plt.figure(figsize=(2,2), dpi=400)\n",
                "sns.histplot(data, bins=20, kde=True)\n",
                "\n",
                "# Add a title and labels to the plot\n",
                "plt.title(\"Sentinel-2B\")\n",
                "plt.xlabel(\"\")\n",
                "plt.ylabel(\"\")\n",
                "# Show the plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Generate histograms for each detector number."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "Sat_col = [coregistration_study_db[coregistration_study_db[\"ID_event\"] ==x][\"Sat\"].to_list()[0] for x in event_names.to_list()]\n",
                "results_df[\"Sat\"]=Sat_col\n",
                "\n",
                "\n",
                "for detector in range(1,13):\n",
                "    generate_histograms(results_df, \"S2A\", detector)\n",
                "    generate_histograms(results_df, \"S2B\", detector)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "py39",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "vscode": {
            "interpreter": {
                "hash": "b92fba3ade83b94b148469d466b202fdab161d6be64369461b773a8ba043abc0"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}